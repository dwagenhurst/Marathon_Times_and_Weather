{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bbbe8ff-49b6-4493-a708-f5e259744621",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8037566a-cbe1-4110-875e-0644355da746",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0be48c-2106-40ed-8092-7238175d0d6f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e26b6d1-35bb-4427-ba05-a522acd6f57e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Boston_Results_2009.csv',\n",
       " 'Boston_Results_2010.csv',\n",
       " 'Boston_Results_2011.csv',\n",
       " 'Boston_Results_2012.csv',\n",
       " 'Boston_Results_2013.csv',\n",
       " 'Boston_Results_2014.csv',\n",
       " 'Boston_Results_2015.csv',\n",
       " 'Boston_Results_2016.csv',\n",
       " 'Boston_Results_2017.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_files = os.listdir('./Boston_Results/Original/')\n",
    "boston_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99c2a190-1bbd-4d47-b98e-3b1b45e9b86a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "boston_09 = pd.read_csv('./Boston_Results/Original/Boston_Results_2009.csv')\n",
    "boston_10 = pd.read_csv('./Boston_Results/Original/Boston_Results_2010.csv')\n",
    "boston_11 = pd.read_csv('./Boston_Results/Original/Boston_Results_2011.csv')\n",
    "boston_12 = pd.read_csv('./Boston_Results/Original/Boston_Results_2012.csv')\n",
    "boston_13 = pd.read_csv('./Boston_Results/Original/Boston_Results_2013.csv')\n",
    "boston_14 = pd.read_csv('./Boston_Results/Original/Boston_Results_2014.csv')\n",
    "boston_15 = pd.read_csv('./Boston_Results/Original/Boston_Results_2015.csv')\n",
    "boston_16 = pd.read_csv('./Boston_Results/Original/Boston_Results_2016.csv')\n",
    "boston_17 = pd.read_csv('./Boston_Results/Original/Boston_Results_2017.csv')\n",
    "\n",
    "# drop problematic row from 2016\n",
    "boston_16 = boston_16.iloc[:-1]\n",
    "\n",
    "# binarize gender\n",
    "boston_09['male'] = np.where(boston_09['M/F'] == 'M', 1, 0)\n",
    "boston_10['male'] = np.where(boston_10['M/F'] == 'M', 1, 0)\n",
    "boston_11['male'] = np.where(boston_11['M/F'] == 'M', 1, 0)\n",
    "boston_12['male'] = np.where(boston_12['M/F'] == 'M', 1, 0)\n",
    "boston_13['male'] = np.where(boston_13['M/F'] == 'M', 1, 0)\n",
    "boston_14['male'] = np.where(boston_14['M/F'] == 'M', 1, 0)\n",
    "boston_15['male'] = np.where(boston_15['M/F'] == 'M', 1, 0)\n",
    "boston_16['male'] = np.where(boston_16['M/F'] == 'M', 1, 0)\n",
    "boston_17['male'] = np.where(boston_17['M/F'] == 'M', 1, 0)\n",
    "\n",
    "# split Official Time into hours, minuts, seconds\n",
    "boston_09['time_h'] = boston_09['Official Time'].str[0].astype(int)\n",
    "boston_10['time_h'] = boston_10['Official Time'].str[0].astype(int)\n",
    "boston_11['time_h'] = boston_11['Official Time'].str[0].astype(int)\n",
    "boston_12['time_h'] = boston_12['Official Time'].str[0].astype(int)\n",
    "boston_13['time_h'] = boston_13['Official Time'].str[0].astype(int)\n",
    "boston_14['time_h'] = boston_14['Official Time'].str[0].astype(int)\n",
    "boston_15['time_h'] = boston_15['Official Time'].str[0].astype(int)\n",
    "boston_16['time_h'] = boston_16['Official Time'].str[0].astype(int)\n",
    "boston_17['time_h'] = boston_17['Official Time'].str[0].astype(int)\n",
    "\n",
    "boston_09['time_m'] = boston_09['Official Time'].str[2:4].astype(int)\n",
    "boston_10['time_m'] = boston_10['Official Time'].str[2:4].astype(int)\n",
    "boston_11['time_m'] = boston_11['Official Time'].str[2:4].astype(int)\n",
    "boston_12['time_m'] = boston_12['Official Time'].str[2:4].astype(int)\n",
    "boston_13['time_m'] = boston_13['Official Time'].str[2:4].astype(int)\n",
    "boston_14['time_m'] = boston_14['Official Time'].str[2:4].astype(int)\n",
    "boston_15['time_m'] = boston_15['Official Time'].str[2:4].astype(int)\n",
    "boston_16['time_m'] = boston_16['Official Time'].str[2:4].astype(int)\n",
    "boston_17['time_m'] = boston_17['Official Time'].str[2:4].astype(int)\n",
    "\n",
    "boston_09['time_s'] = boston_09['Official Time'].str[5:].astype(int)\n",
    "boston_10['time_s'] = boston_10['Official Time'].str[5:].astype(int)\n",
    "boston_11['time_s'] = boston_11['Official Time'].str[5:].astype(int)\n",
    "boston_12['time_s'] = boston_12['Official Time'].str[5:].astype(int)\n",
    "boston_13['time_s'] = boston_13['Official Time'].str[5:].astype(int)\n",
    "boston_14['time_s'] = boston_14['Official Time'].str[5:].astype(int)\n",
    "boston_15['time_s'] = boston_15['Official Time'].str[5:].astype(int)\n",
    "boston_16['time_s'] = boston_16['Official Time'].str[5:].astype(int)\n",
    "boston_17['time_s'] = boston_17['Official Time'].str[5:].astype(int)\n",
    "\n",
    "# combine split times into total seconds\n",
    "boston_09['time_seconds'] = boston_09['time_s'] + (boston_09['time_m'] * 60) + (boston_09['time_h'] * 60 * 60)\n",
    "boston_10['time_seconds'] = boston_10['time_s'] + (boston_10['time_m'] * 60) + (boston_10['time_h'] * 60 * 60)\n",
    "boston_11['time_seconds'] = boston_11['time_s'] + (boston_11['time_m'] * 60) + (boston_11['time_h'] * 60 * 60)\n",
    "boston_12['time_seconds'] = boston_12['time_s'] + (boston_12['time_m'] * 60) + (boston_12['time_h'] * 60 * 60)\n",
    "boston_13['time_seconds'] = boston_13['time_s'] + (boston_13['time_m'] * 60) + (boston_13['time_h'] * 60 * 60)\n",
    "boston_14['time_seconds'] = boston_14['time_s'] + (boston_14['time_m'] * 60) + (boston_14['time_h'] * 60 * 60)\n",
    "boston_15['time_seconds'] = boston_15['time_s'] + (boston_15['time_m'] * 60) + (boston_15['time_h'] * 60 * 60)\n",
    "boston_16['time_seconds'] = boston_16['time_s'] + (boston_16['time_m'] * 60) + (boston_16['time_h'] * 60 * 60)\n",
    "boston_17['time_seconds'] = boston_17['time_s'] + (boston_17['time_m'] * 60) + (boston_17['time_h'] * 60 * 60)\n",
    "\n",
    "# drop unnecessary columns\n",
    "drop_cols15 = ['Unnamed: 0', 'Bib', 'Name', 'M/F', 'City', 'State', 'Country',\n",
    "       'Citizen', 'Unnamed: 9', '5K', '10K', '15K', '20K', 'Half', '25K',\n",
    "       '30K', '35K', '40K', 'Pace', 'Proj Time', 'Official Time', 'Overall',\n",
    "       'Gender', 'Division', 'time_h', 'time_m', 'time_s']\n",
    "\n",
    "drop_cols = ['Unnamed: 8', 'Bib', 'Name', 'M/F', 'City', 'State', 'Country',\n",
    "       'Citizen', '5K', '10K', '15K', '20K', 'Half', '25K',\n",
    "       '30K', '35K', '40K', 'Pace', 'Proj Time', 'Official Time', 'Overall',\n",
    "       'Gender', 'Division', 'time_h', 'time_m', 'time_s']\n",
    "\n",
    "boston_09_clean = boston_09.drop(columns=drop_cols)\n",
    "boston_10_clean = boston_10.drop(columns=drop_cols)\n",
    "boston_11_clean = boston_11.drop(columns=drop_cols)\n",
    "boston_12_clean = boston_12.drop(columns=drop_cols)\n",
    "boston_13_clean = boston_13.drop(columns=drop_cols)\n",
    "boston_14_clean = boston_14.drop(columns=drop_cols)\n",
    "boston_15_clean = boston_15.drop(columns=drop_cols15)\n",
    "boston_16_clean = boston_16.drop(columns=drop_cols)\n",
    "boston_17_clean = boston_17.drop(columns=drop_cols)\n",
    "\n",
    "# adjust column names\n",
    "boston_09_clean.columns = ['age', 'male', 'time_seconds']\n",
    "boston_10_clean.columns = ['age', 'male', 'time_seconds']\n",
    "boston_11_clean.columns = ['age', 'male', 'time_seconds']\n",
    "boston_12_clean.columns = ['age', 'male', 'time_seconds']\n",
    "boston_13_clean.columns = ['age', 'male', 'time_seconds']\n",
    "boston_14_clean.columns = ['age', 'male', 'time_seconds']\n",
    "boston_15_clean.columns = ['age', 'male', 'time_seconds']\n",
    "boston_16_clean.columns = ['age', 'male', 'time_seconds']\n",
    "boston_17_clean.columns = ['age', 'male', 'time_seconds']\n",
    "\n",
    "\n",
    "# add year column\n",
    "boston_09_clean['year'] = 2009\n",
    "boston_10_clean['year'] = 2010\n",
    "boston_11_clean['year'] = 2011\n",
    "boston_12_clean['year'] = 2012\n",
    "boston_13_clean['year'] = 2013\n",
    "boston_14_clean['year'] = 2014\n",
    "boston_15_clean['year'] = 2015\n",
    "boston_16_clean['year'] = 2016\n",
    "boston_17_clean['year'] = 2017\n",
    "\n",
    "\n",
    "# combine\n",
    "boston_combined = pd.concat([boston_09_clean, boston_10_clean, boston_11_clean, \n",
    "                             boston_12_clean, boston_13_clean, boston_14_clean, \n",
    "                             boston_15_clean, boston_16_clean, boston_17_clean], ignore_index=True)\n",
    "\n",
    "# reduce size\n",
    "boston_combined['year'] = pd.to_numeric(boston_combined['year'], downcast='unsigned')\n",
    "boston_combined['time_seconds'] = pd.to_numeric(boston_combined['time_seconds'], downcast='unsigned')\n",
    "boston_combined['male'] = pd.to_numeric(boston_combined['male'], downcast='unsigned')\n",
    "boston_combined['age'] = pd.to_numeric(boston_combined['age'], downcast='unsigned')\n",
    "\n",
    "\n",
    "\n",
    "# save to csv\n",
    "boston_09_clean.to_csv('./Boston_Results/Clean/Clean_Boston_Results_2009.csv', index=False)\n",
    "boston_10_clean.to_csv('./Boston_Results/Clean/Clean_Boston_Results_2010.csv', index=False)\n",
    "boston_11_clean.to_csv('./Boston_Results/Clean/Clean_Boston_Results_2011.csv', index=False)\n",
    "boston_12_clean.to_csv('./Boston_Results/Clean/Clean_Boston_Results_2012.csv', index=False)\n",
    "boston_13_clean.to_csv('./Boston_Results/Clean/Clean_Boston_Results_2013.csv', index=False)\n",
    "boston_14_clean.to_csv('./Boston_Results/Clean/Clean_Boston_Results_2014.csv', index=False)\n",
    "boston_15_clean.to_csv('./Boston_Results/Clean/Clean_Boston_Results_2015.csv', index=False)\n",
    "boston_16_clean.to_csv('./Boston_Results/Clean/Clean_Boston_Results_2016.csv', index=False)\n",
    "boston_17_clean.to_csv('./Boston_Results/Clean/Clean_Boston_Results_2017.csv', index=False)\n",
    "\n",
    "boston_combined.to_csv('./Boston_Results/Clean/Clean_Boston_Results_Combined.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b546197-216d-4328-8f2b-0310caca3942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 190437 entries, 0 to 190436\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   age           190437 non-null  uint8 \n",
      " 1   male          190437 non-null  uint8 \n",
      " 2   time_seconds  190437 non-null  uint16\n",
      " 3   year          190437 non-null  uint16\n",
      "dtypes: uint16(2), uint8(2)\n",
      "memory usage: 1.1 MB\n"
     ]
    }
   ],
   "source": [
    "boston_combined.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57dd585-54b2-4dd2-b693-ab352ef618b3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## NYC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a13e4f34-2463-4a26-a1a7-3c5f8495a5aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NYC_Results_2014.csv',\n",
       " 'NYC_Results_2015.csv',\n",
       " 'NYC_Results_2016.csv',\n",
       " 'NYC_Results_2017.csv',\n",
       " 'NYC_Results_2018.csv',\n",
       " 'NYC_Results_2021.csv']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyc_files = os.listdir('./NYC_Results/Original/')\n",
    "nyc_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2e8c2e6-b707-4103-b4b2-b87e63929268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in files\n",
    "nyc_14 = pd.read_csv('./NYC_Results/Original/NYC_Results_2014.csv')\n",
    "nyc_15 = pd.read_csv('./NYC_Results/Original/NYC_Results_2015.csv')\n",
    "nyc_16 = pd.read_csv('./NYC_Results/Original/NYC_Results_2016.csv')\n",
    "nyc_17 = pd.read_csv('./NYC_Results/Original/NYC_Results_2017.csv')\n",
    "nyc_18 = pd.read_csv('./NYC_Results/Original/NYC_Results_2018.csv')\n",
    "nyc_21 = pd.read_csv('./NYC_Results/Original/NYC_Results_2021.csv')\n",
    "\n",
    "# split groups into age and binarize gender\n",
    "nyc_14['age'] = nyc_14['groups'].str[1:].astype(int)\n",
    "nyc_15['age'] = nyc_15['groups'].str[1:].astype(int)\n",
    "nyc_16['age'] = nyc_16['groups'].str[1:].astype(int)\n",
    "nyc_17['age'] = nyc_17['groups'].str[1:].astype(int)\n",
    "nyc_18['age'] = nyc_18['groups'].str[1:].astype(int)\n",
    "nyc_21['age'] = nyc_21['groups'].str[1:].astype(int)\n",
    "\n",
    "nyc_14['male'] = np.where(nyc_14['groups'].str[0] == 'M', 1, 0)\n",
    "nyc_15['male'] = np.where(nyc_15['groups'].str[0] == 'M', 1, 0)\n",
    "nyc_16['male'] = np.where(nyc_16['groups'].str[0] == 'M', 1, 0)\n",
    "nyc_17['male'] = np.where(nyc_17['groups'].str[0] == 'M', 1, 0)\n",
    "nyc_18['male'] = np.where(nyc_18['groups'].str[0] == 'M', 1, 0)\n",
    "nyc_21['male'] = np.where(nyc_21['groups'].str[0] == 'M', 1, 0)\n",
    "\n",
    "# split time into hours, minutes, seconds\n",
    "nyc_14['time_h'] = nyc_14['times'].str[0].astype(int)\n",
    "nyc_15['time_h'] = nyc_15['times'].str[0].astype(int)\n",
    "nyc_16['time_h'] = nyc_16['times'].str[0].astype(int)\n",
    "nyc_17['time_h'] = nyc_17['times'].str[0].astype(int)\n",
    "nyc_18['time_h'] = nyc_18['times'].str[0].astype(int)\n",
    "nyc_21['time_h'] = nyc_21['times'].str[0].astype(int)\n",
    "\n",
    "nyc_14['time_m'] = nyc_14['times'].str[2:4].astype(int)\n",
    "nyc_15['time_m'] = nyc_15['times'].str[2:4].astype(int)\n",
    "nyc_16['time_m'] = nyc_16['times'].str[2:4].astype(int)\n",
    "nyc_17['time_m'] = nyc_17['times'].str[2:4].astype(int)\n",
    "nyc_18['time_m'] = nyc_18['times'].str[2:4].astype(int)\n",
    "nyc_21['time_m'] = nyc_21['times'].str[2:4].astype(int)\n",
    "\n",
    "nyc_14['time_s'] = nyc_14['times'].str[5:].astype(int)\n",
    "nyc_15['time_s'] = nyc_15['times'].str[5:].astype(int)\n",
    "nyc_16['time_s'] = nyc_16['times'].str[5:].astype(int)\n",
    "nyc_17['time_s'] = nyc_17['times'].str[5:].astype(int)\n",
    "nyc_18['time_s'] = nyc_18['times'].str[5:].astype(int)\n",
    "nyc_21['time_s'] = nyc_21['times'].str[5:].astype(int)\n",
    "\n",
    "# combine split times into total seconds\n",
    "nyc_14['time_seconds'] = nyc_14['time_s'] + (nyc_14['time_m'] * 60) + (nyc_14['time_h'] * 60 * 60)\n",
    "nyc_15['time_seconds'] = nyc_15['time_s'] + (nyc_15['time_m'] * 60) + (nyc_15['time_h'] * 60 * 60)\n",
    "nyc_16['time_seconds'] = nyc_16['time_s'] + (nyc_16['time_m'] * 60) + (nyc_16['time_h'] * 60 * 60)\n",
    "nyc_17['time_seconds'] = nyc_17['time_s'] + (nyc_17['time_m'] * 60) + (nyc_17['time_h'] * 60 * 60)\n",
    "nyc_18['time_seconds'] = nyc_18['time_s'] + (nyc_18['time_m'] * 60) + (nyc_18['time_h'] * 60 * 60)\n",
    "nyc_21['time_seconds'] = nyc_21['time_s'] + (nyc_21['time_m'] * 60) + (nyc_21['time_h'] * 60 * 60)\n",
    "\n",
    "# drop unnecessary columns\n",
    "nyc_14.drop(columns=['groups', 'times', 'time_h', 'time_m', 'time_s'], inplace=True)\n",
    "nyc_15.drop(columns=['groups', 'times', 'time_h', 'time_m', 'time_s'], inplace=True)\n",
    "nyc_16.drop(columns=['groups', 'times', 'time_h', 'time_m', 'time_s'], inplace=True)\n",
    "nyc_17.drop(columns=['groups', 'times', 'time_h', 'time_m', 'time_s'], inplace=True)\n",
    "nyc_18.drop(columns=['groups', 'times', 'time_h', 'time_m', 'time_s'], inplace=True)\n",
    "nyc_21.drop(columns=['groups', 'times', 'time_h', 'time_m', 'time_s'], inplace=True)\n",
    "\n",
    "# add year column\n",
    "nyc_14['year'] = 2014\n",
    "nyc_15['year'] = 2015\n",
    "nyc_16['year'] = 2016\n",
    "nyc_17['year'] = 2017\n",
    "nyc_18['year'] = 2018\n",
    "nyc_21['year'] = 2021\n",
    "\n",
    "# combine\n",
    "nyc_combined = pd.concat([nyc_14, nyc_15, nyc_16, nyc_17, nyc_18, nyc_21], ignore_index=True)\n",
    "\n",
    "# reduce size\n",
    "nyc_combined['year'] = pd.to_numeric(nyc_combined['year'], downcast='unsigned')\n",
    "nyc_combined['time_seconds'] = pd.to_numeric(nyc_combined['time_seconds'], downcast='unsigned')\n",
    "nyc_combined['male'] = pd.to_numeric(nyc_combined['male'], downcast='unsigned')\n",
    "nyc_combined['age'] = pd.to_numeric(nyc_combined['age'], downcast='unsigned')\n",
    "\n",
    "\n",
    "# save cleaned sets to csv\n",
    "nyc_14.to_csv('./NYC_Results/Clean/Clean_NYC_Results_2014.csv', index=False)\n",
    "nyc_15.to_csv('./NYC_Results/Clean/Clean_NYC_Results_2015.csv', index=False)\n",
    "nyc_16.to_csv('./NYC_Results/Clean/Clean_NYC_Results_2016.csv', index=False)\n",
    "nyc_17.to_csv('./NYC_Results/Clean/Clean_NYC_Results_2017.csv', index=False)\n",
    "nyc_18.to_csv('./NYC_Results/Clean/Clean_NYC_Results_2018.csv', index=False)\n",
    "nyc_21.to_csv('./NYC_Results/Clean/Clean_NYC_Results_2021.csv', index=False)\n",
    "\n",
    "nyc_combined.to_csv('./NYC_Results/Clean/Clean_NYC_Results_Combined.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb0ad507-6b01-4638-993e-d6398508d364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59975 entries, 0 to 59974\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   age           59975 non-null  uint8 \n",
      " 1   male          59975 non-null  uint8 \n",
      " 2   time_seconds  59975 non-null  uint16\n",
      " 3   year          59975 non-null  uint16\n",
      "dtypes: uint16(2), uint8(2)\n",
      "memory usage: 351.5 KB\n"
     ]
    }
   ],
   "source": [
    "nyc_combined.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faacf87a-a4e5-48c5-8d21-7955025b15dd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Berlin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3de12a7-e534-4407-a4a3-554d8a5f14dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Berlin_Marathon_data_1974_2019.csv',\n",
       " 'Berlin_Marathon_data_1974_2019_alt.csv',\n",
       " 'Berlin_Marathon_weather_data_since_1974.csv']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "berlin_files = os.listdir('./Berlin_Results/Original/')\n",
    "berlin_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2829e630-a7c2-4486-b558-2712f0d3a09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: DtypeWarning: Columns (1) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "berlin = pd.read_csv('./Berlin_Results/Original/Berlin_Marathon_data_1974_2019_alt.csv')\n",
    "\n",
    "# binarize gender\n",
    "berlin['male'] = np.where(berlin['GENDER'] == 'male', 1, 0)\n",
    "\n",
    "\n",
    "# drop rows with no time\n",
    "berlin = pd.DataFrame(berlin[berlin['TIME'] != 'no time'])\n",
    "\n",
    "# split time into hours, minutes, seconds\n",
    "berlin['time_h'] = berlin['TIME'].str[0].astype(int)\n",
    "berlin['time_m'] = berlin['TIME'].str[2:4].astype(int)\n",
    "berlin['time_s'] = berlin['TIME'].str[5:].astype(int)\n",
    "\n",
    "\n",
    "# combine split times into total seconds\n",
    "berlin['time_seconds'] = berlin['time_s'] + (berlin['time_m'] * 60) + (berlin['time_h'] * 60 * 60)\n",
    "\n",
    "\n",
    "# drop unnecessary columns\n",
    "berlin.drop(columns=['COUNTRY', 'TIME', 'GENDER', 'time_h', 'time_m', 'time_s'], inplace=True)\n",
    "\n",
    "# adjust column names\n",
    "berlin.columns = ['year', 'age', 'male', 'time_seconds']\n",
    "\n",
    "# reduce size\n",
    "berlin['year'] = pd.to_numeric(berlin['year'], downcast='unsigned')\n",
    "berlin['age'] = pd.to_numeric(berlin['age'], downcast='unsigned')\n",
    "berlin['male'] = pd.to_numeric(berlin['male'], downcast='unsigned')\n",
    "berlin['time_seconds'] = pd.to_numeric(berlin['time_seconds'], downcast='unsigned')\n",
    "\n",
    "# save cleaned sets to csv\n",
    "berlin.to_csv('./Berlin_Results/Clean/Clean_Berlin_Results_1974_2019.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1aff0767-12b8-40d4-a9b6-34fd557fc274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 869474 entries, 0 to 871182\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   year          869474 non-null  uint16\n",
      " 1   age           869474 non-null  uint8 \n",
      " 2   male          869474 non-null  uint8 \n",
      " 3   time_seconds  869474 non-null  uint16\n",
      "dtypes: uint16(2), uint8(2)\n",
      "memory usage: 11.6 MB\n"
     ]
    }
   ],
   "source": [
    "berlin.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
